{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee8170a",
   "metadata": {},
   "source": [
    "## SECTION 1: API - Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e9939a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_departments = \"departments.csv\"\n",
    "path_hired_employees = \"hired_employees.csv\"\n",
    "path_jobs = \"jobs.csv\"\n",
    "\n",
    "table_departments = 'departments'\n",
    "columns_departments = ['id_departments', 'department']\n",
    "table_employees = 'employees'\n",
    "columns_employees = ['id_hired_employees', 'hired_employees', 'hired_date', 'department', 'job']\n",
    "table_jobs = 'jobs'\n",
    "columns_jobs = ['id_job', 'job']\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "delimiter = \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5d255638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(path: str, delimiter: str, table_name: str, column_names: list ,batch_size) -> None:\n",
    "    \"\"\"\n",
    "    Main function to read a CSV file and insert its data into a database table.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): The path to the CSV file to read.\n",
    "    delimiter (str): The delimiter used in the CSV file.\n",
    "    table_name (str): The name of the database table where the data will be inserted.\n",
    "    batch_size (int): The number of rows to insert in each batch. Default is 1000.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    df = read_csv_with_error_handling(path, delimiter)\n",
    "    \n",
    "    if df is not None:\n",
    "        try:\n",
    "            _data_to_db(table_name, df, batch_size, column_names)\n",
    "        except Exception as error:\n",
    "            print(f\"Error inserting data into the database: {error}\")\n",
    "    else:\n",
    "        print(\"Data was not read from the CSV file due to an error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "34bb19ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table successfully truncated.\n",
      "Data inserted into the database successfully!\n"
     ]
    }
   ],
   "source": [
    "main(path_jobs, delimiter, table_jobs, columns_jobs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c47a2",
   "metadata": {},
   "source": [
    "## SECTION 1: API - Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad577d",
   "metadata": {},
   "source": [
    "### 1. ExtracciÃ³n de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f4fa5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e749b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_csv_with_error_handling(file_path: str, separator: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a CSV file and displays its content in a DataFrame.\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "        separator (str): The delimiter used in the CSV file to separate fields.\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing the content of the CSV file.\n",
    "    Raises:\n",
    "        FileNotFoundError: If the file is not found at the specified path.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a Spark session\n",
    "        logging.info(\"Initializing Spark session\")\n",
    "        spark = SparkSession.builder.appName(\"ReadCSV\").getOrCreate()\n",
    "\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = spark.read.csv(file_path, header=False, inferSchema=True, sep=separator)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except AnalysisException as e:\n",
    "        # Handle the exception if the file is not found\n",
    "        raise FileNotFoundError(f\"File not found at path: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21a86ef",
   "metadata": {},
   "source": [
    "### 2. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da283d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _db_connection():\n",
    "    \"\"\"\n",
    "    Open a connection to the PostgreSQL database.\n",
    "    Returns:\n",
    "        conn (psycopg2.extensions.connection): PostgreSQL database connection object.\n",
    "    \"\"\"\n",
    "    # Establish a connection to the PostgreSQL database\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"postgres\",\n",
    "        password=\"postgrespass\",\n",
    "        database=\"postgres\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    \n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0414d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _truncate_table(table_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Truncate (empty) an existing table in the database.\n",
    "    Args:\n",
    "        table_name (str): The name of the table to be truncated.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Open a connection to the database\n",
    "    conn = db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Empty the existing table\n",
    "    truncate_query = f\"TRUNCATE TABLE {table_name}\"\n",
    "    cursor.execute(truncate_query)\n",
    "    conn.commit()\n",
    "    print(\"Table successfully truncated.\")\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1bd83d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _data_to_db(table_name: str, df_data: DataFrame, batch_size: int, column_names: list) -> None:\n",
    "    \"\"\"\n",
    "    Insert data from a Pandas DataFrame into a specified database table.\n",
    "\n",
    "    Parameters:\n",
    "    table_name (str): The name of the database table where the data will be inserted.\n",
    "    df_data (DataFrame): The DataFrame containing the data to be inserted.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    if not (1 <= batch_size <= 1000):\n",
    "        raise ValueError(\"batch_size must be between 1 and 1000.\")\n",
    "    \n",
    "    # Open a connection to the database\n",
    "    conn = db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    df_data= df_data.toDF(*column_names)\n",
    "    df_data = df_data.toPandas()\n",
    "\n",
    "    # Empty the existing table\n",
    "    truncate_table(table_name)\n",
    "\n",
    "   # Create a list of tuples from the DataFrame\n",
    "    tuples = [tuple(x) for x in df_data.to_numpy()]\n",
    "\n",
    "    # Get the column names\n",
    "    cols = ','.join(list(df_data.columns))\n",
    "\n",
    "     # Create the SQL statement\n",
    "    query = f\"INSERT INTO {table_name}({cols}) VALUES %s\"\n",
    "    \n",
    "    # Insert data in batches\n",
    "    for i in range(0, len(tuples), batch_size):\n",
    "        batch = tuples[i:i + batch_size]\n",
    "        try:\n",
    "            extras.execute_values(cursor, query, batch)\n",
    "            conn.commit()            \n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(\"Error: %s\" % error)\n",
    "            conn.rollback()\n",
    "    \n",
    "    \n",
    "    conn.close()\n",
    "    print(\"Data inserted into the database successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
